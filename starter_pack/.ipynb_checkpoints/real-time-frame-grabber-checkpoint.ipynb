{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align import AlignDlib\n",
    "alignment = AlignDlib(\"models/landmarks.dat\")\n",
    "def align_image(img):\n",
    "    return alignment.align(96, img, alignment.getLargestFaceBoundingBox(img), \n",
    "                           landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "[[[116 133 151]\n",
      "  [113 129 147]\n",
      "  [109 126 144]\n",
      "  ...\n",
      "  [ 88 101 115]\n",
      "  [ 93 107 121]\n",
      "  [ 93 107 121]]\n",
      "\n",
      " [[116 133 151]\n",
      "  [114 131 148]\n",
      "  [110 127 145]\n",
      "  ...\n",
      "  [ 85  99 113]\n",
      "  [ 93 107 121]\n",
      "  [ 99 113 126]]\n",
      "\n",
      " [[117 134 152]\n",
      "  [117 134 152]\n",
      "  [116 133 151]\n",
      "  ...\n",
      "  [ 84 100 114]\n",
      "  [ 94 110 121]\n",
      "  [ 96 113 124]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[100 110 127]\n",
      "  [102 113 129]\n",
      "  [103 114 130]\n",
      "  ...\n",
      "  [ 93  93 106]\n",
      "  [ 66  66  79]\n",
      "  [ 57  56  70]]\n",
      "\n",
      " [[102 113 129]\n",
      "  [103 114 130]\n",
      "  [110 121 137]\n",
      "  ...\n",
      "  [105 105 119]\n",
      "  [ 84  84  98]\n",
      "  [ 66  66  79]]\n",
      "\n",
      " [[106 116 133]\n",
      "  [102 113 129]\n",
      "  [109 120 136]\n",
      "  ...\n",
      "  [107 107 120]\n",
      "  [ 98  98 112]\n",
      "  [ 73  73  86]]]\n",
      "[INFO] elasped time: 405.45\n",
      "[INFO] approx. FPS: 18.08\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# initialize the video stream, then allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    " \n",
    "# start the FPS throughput estimator\n",
    "fps = FPS().start()\n",
    "count =0\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "# grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "    if count == 0: \n",
    "        print(frame)\n",
    "        count+=1\n",
    "    # resize the frame to have a width of 600 pixels (while\n",
    "    # maintaining the aspect ratio), and then grab the image\n",
    "    # dimensions\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    \n",
    "    blobs = alignment.getAllFaceBoundingBoxes(frame)\n",
    "    for blob in blobs:        \n",
    "        img = align_image(blob)\n",
    "        # scale RGB values to interval [0,1]\n",
    "        img = (img / 255.).astype(np.float32)\n",
    "        embeded = ___.predict\n",
    "        ## cross check embeded lists\n",
    "        \n",
    "        \n",
    "    # construct a blob from the image\n",
    "    imageBlob = cv2.dnn.blobFromImage(\n",
    "    cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
    "    (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    # apply OpenCV's deep learning-based face detector to localize\n",
    "    # # faces in the input image\n",
    "    # detector.setInput(imageBlob)\n",
    "    # detections = detector.forward()\n",
    "    # loop over the detections\n",
    "    # for i in range(0, detections.shape[2]):\n",
    "    # # extract the confidence (i.e., probability) associated with\n",
    "    # # the prediction\n",
    "    # confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # # filter out weak detections\n",
    "    # if confidence > args[\"confidence\"]:\n",
    "    # # compute the (x, y)-coordinates of the bounding box for\n",
    "    # # the face\n",
    "    # box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "    # (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "    # # extract the face ROI\n",
    "    # face = frame[startY:endY, startX:endX]\n",
    "    # (fH, fW) = face.shape[:2]\n",
    "\n",
    "    # # ensure the face width and height are sufficiently large\n",
    "    # if fW < 20 or fH < 20:\n",
    "        # continue\n",
    "    #   # construct a blob for the face ROI, then pass the blob\n",
    "    # # through our face embedding model to obtain the 128-d\n",
    "    # # quantification of the face\n",
    "    # faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255,\n",
    "    # (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    # embedder.setInput(faceBlob)\n",
    "    # vec = embedder.forward()\n",
    "\n",
    "    # # perform classification to recognize the face\n",
    "    # preds = recognizer.predict_proba(vec)[0]\n",
    "    # j = np.argmax(preds)\n",
    "    # proba = preds[j]\n",
    "    # name = le.classes_[j]\n",
    "\n",
    "    # # draw the bounding box of the face along with the\n",
    "    # # associated probability\n",
    "    # text = \"{}: {:.2f}%\".format(name, proba * 100)\n",
    "    # y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    # cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "    # (0, 0, 255), 2)\n",
    "    # cv2.putText(frame, text, (startX, y),\n",
    "    # cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "    # update the FPS counter\n",
    "    fps.update()\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    " \n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
